{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json \n",
    "\n",
    "# Path\n",
    "path_raw = r'C:/Users/Usuario/Documents/b4d/data/raw/'\n",
    "path_processed = r'C:/Users/Usuario/Documents/b4d/data/processed/'\n",
    "\n",
    "# Name of file\n",
    "file_name = 'fairplay_connectly_report_wk2'\n",
    "\n",
    "# file_name_base = 'tigobo_1804-Internet Inicial 2-Wpp'\n",
    "\n",
    "# File extension\n",
    "file_extension = '.csv'\n",
    "\n",
    "# Suffix to proceseed files\n",
    "suffix = '_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1196, 9)\n"
     ]
    }
   ],
   "source": [
    "# Reading reporte csv\n",
    "# Columns\n",
    "columns = ['customer_external_id', 'campaign_name', 'dispatched_at', 'sent_at', 'delivered_at', 'read_at', 'error_code', 'error_msg', 'link_clicks']\n",
    "\n",
    "# Reading csv to dataframe\n",
    "df = pd.read_csv(path_raw+file_name+file_extension, usecols=columns)\n",
    "print(f\"Shape:  {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional)\n",
    "# Reading base/original csv\n",
    "# Columns\n",
    "columns_base = ['PhoneNumber']\n",
    "\n",
    "# Reading csv to dataframe\n",
    "df_base = pd.read_csv(path_raw+file_name_base+file_extension, usecols=columns_base)\n",
    "print(f\"Shape:  {df_base.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional)\n",
    "# Analysis 1.1\n",
    "# why some phone number was not sent the difussion message\n",
    "df_diff = df_base[~df_base['PhoneNumber'].isin(df['customer_external_id'])]\n",
    "print(f\"Shape:  {df_diff.shape}\")\n",
    "\n",
    "suffix_diff = '_not_merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix 1.1 - Febrero\n",
    "# replace name test campaing in order to follow the rule\n",
    "#df['campaign_name'] = np.where(df['campaign_name']=='Cambio de caracteristicas de planes movil Postpago_Mega Plan 169_21022025', 'Cambio De Caracteristicas De Planes Movil Postpago Mega Plan 169 21022025 . Prueba',df['campaign_name'])\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix 2.1\n",
    "# Exclude some campaigns beacuse it was error sending\n",
    "#df = df[df['campaign_name']!='Comunicacion Por Whatsapp Recordatorio Cambio De Caracteristicas Movil Mega Plan 180 Mega Plan 225 Mega Plan 299 Mega Plan 305 . Planes Movil Postpago Mega Plan 299 . 21 02 25 . Lote']\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df = df[df['campaign_name'].isin(['Datos Empresa Oc Mensajeria . Bridgeconnectly web . 23 05 25 . Prueba', 'Datos Empresa Oc Mensajeria . Bridgeconnectly Wapp . 23 05 25 . Lote2', 'Datos Empresa Oc Mensajeria . Bridgeconnectly wapp . 23 05 25 . lote1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper name for all name campaigns\n",
    "df['campaign_name'] = df['campaign_name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating the campaign name\n",
    "# Regexs\n",
    "#regex_1 = r'\\s*?\\.?\\s*?(BATCH|NORMAL|CX|LOTE|LOT|LO|COPY).*$'\n",
    "regex_1 = r'\\s*?\\.?\\s*?(BATCH|NORMAL|CX|LOTE|LOT|COPY).*$'\n",
    "regex_2 = r'\\.\\s\\d{2}$'\n",
    "regex_3 = r'\\s*?\\.?\\s*?(OK|ENVIO OK|ENVIO|PRUEBA INTERNA|PRUEBA)\\s?\\d*?$'\n",
    "regex_4 = r'\\.?\\s?PRUEBA\\s?'\n",
    "\n",
    "# Function to extraction string with regex\n",
    "def f_regex(data_str, regex, str_replace=''):\n",
    "    return re.sub(regex, str_replace, data_str, flags=re.IGNORECASE)\n",
    "\n",
    "# Applying the regex with the campaing name column\n",
    "df['campaign_name_base'] = df['campaign_name'].apply(lambda x: f_regex(x, regex_1))\n",
    "df['campaign_name_base'] = df['campaign_name_base'].apply(lambda x: f_regex(x, regex_2))\n",
    "df['campaign_name_base'] = df['campaign_name_base'].apply(lambda x: f_regex(x, regex_3))\n",
    "df['campaign_name_base'] = df['campaign_name_base'].apply(lambda x: f_regex(x, regex_4))\n",
    "\n",
    "# Verify if this campaign is test\n",
    "# df['tipo'] = np.where(df['campaign_name'].str.contains('PRUEBA', na=False), 'PRUEBA', 'LOTE')\n",
    "\n",
    "# Filter to verify if this message was error\n",
    "# This filter was used in excel and below is equivalent with pandas\n",
    "# =O(ESBLANCO([@[error_code]]);NO(ESBLANCO([@[read_at]]));NO(ESBLANCO([@[delivered_at]]));NO(ESBLANCO([@[sent_at]])))\n",
    "filter_delivered = (\n",
    "   # df['error_code'].isna() |                  \n",
    "    df['read_at'].notna() |                    \n",
    "    df['delivered_at'].notna() \n",
    "   # | df['sent_at'].notna()                      \n",
    ")\n",
    "df['delivered'] = np.where(filter_delivered, 'TRUE', 'FALSE')\n",
    "\n",
    "df['read'] = np.where(df['read_at'].notna(), 'TRUE', 'FALSE')\n",
    "\n",
    "# old code\n",
    "#df['estado'] = ~((df['error_code'] == '') | ~(df['error_code'].isna()))\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex_5 = r'Compra por Whatsapp'\n",
    "\n",
    "# df['buy_wsp'] = np.where(df['link_clicks'].str.contains(regex_5, case=True, regex=True, na=False), 'TRUE', 'FALSE')\n",
    "\n",
    "# regex_6 = r'Compra por web'\n",
    "\n",
    "# df['buy_web'] = np.where(df['link_clicks'].str.contains(regex_6, case=True, regex=True, na=False), 'TRUE', 'FALSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['link_clicks'] = df['link_clicks'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_name(json_str):\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        data_sorted = sorted(data, key=lambda x: x[\"ts\"])\n",
    "        return data_sorted[0][\"name\"] if isinstance(data_sorted, list) and len(data_sorted) > 0 else None\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        return None\n",
    "    \n",
    "df['buy_wsp'] = np.where(df['link_clicks'].apply(get_first_name) == \"Compra por Whatsapp\", \"TRUE\", \"FALSE\")\n",
    "df['buy_web'] = np.where(df['link_clicks'].apply(get_first_name) == \"Compra por web\", \"TRUE\", \"FALSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"buy_wsp_count\"] = df[\"link_clicks\"].apply(\n",
    "    lambda x: sum(1 for event in json.loads(x) if isinstance(event, dict) and event[\"name\"] == \"Compra por Whatsapp\")\n",
    "    if x != 'nan' and pd.notna(x) and x.strip() != \"\" else 0\n",
    ")\n",
    "\n",
    "df[\"buy_web_count\"] = df[\"link_clicks\"].apply(\n",
    "    lambda x: sum(1 for event in json.loads(x) if isinstance(event, dict) and event[\"name\"] == \"Compra por web\")\n",
    "    if x != 'nan' and pd.notna(x) and x.strip() != \"\" else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df['engagement'] = df[\"buy_wsp_count\"] + df[\"buy_web_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def date_assign(name):\n",
    "    if name in ['DATOS EMPRESA OC MENSAJERIA . BRIDGECONNECTLY WAPP . 23 05 25 . LOTE3']:\n",
    "        return pd.to_datetime('2025-05-26 12:00')\n",
    "    elif name in ['DATOS EMPRESA OC MENSAJERIA . BRIDGECONNECTLY WEB . 23 05 25 . LOTE2']:\n",
    "        return pd.to_datetime('2025-05-26 12:00')\n",
    "    else:\n",
    "        return pd.NaT \n",
    "    \n",
    "df['date'] = df['campaign_name'].apply(date_assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['date'].dt.day_name(locale='es_ES')\n",
    "df['hour'] = df['date'].dt.strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tipo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Usuario\\.virtualenvs\\b4d_analytics-Yg60_lpz\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tipo'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m df_tmp \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m df_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdummy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcrosstab(\n\u001b[0;32m      6\u001b[0m         [df_tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcampaign_name_base\u001b[39m\u001b[38;5;124m'\u001b[39m]], \n\u001b[1;32m----> 7\u001b[0m         \u001b[43mdf_tmp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtipo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \n\u001b[0;32m      8\u001b[0m         margins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     )\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     10\u001b[0m result\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\.virtualenvs\\b4d_analytics-Yg60_lpz\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\.virtualenvs\\b4d_analytics-Yg60_lpz\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tipo'"
     ]
    }
   ],
   "source": [
    "# Count message for each campaigns\n",
    "#df.groupby('campaign_name_base', as_index=False).size()\n",
    "df_tmp = df.copy()\n",
    "df_tmp['dummy'] = 1\n",
    "result = pd.crosstab(\n",
    "        [df_tmp['campaign_name_base']], \n",
    "        df_tmp['tipo'], \n",
    "        margins=True\n",
    "    ).reset_index()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total by error code\n",
    "#df.groupby(['error_code', 'error_msg'], as_index=False).size()\n",
    "\n",
    "df_tmp = df.copy()\n",
    "df_tmp['dummy'] = 1\n",
    "result = pd.crosstab(\n",
    "        [df_tmp['error_code'], df_tmp['error_msg']], \n",
    "        df_tmp['dummy'], \n",
    "        margins=True\n",
    "    ).reset_index()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total by estado\n",
    "#df.groupby('estado', as_index=False).size()\n",
    "\n",
    "df_tmp = df.copy()\n",
    "df_tmp['dummy'] = 1\n",
    "result = pd.crosstab([df_tmp['estado']],df_tmp['dummy'],margins=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change error code\n",
    "# Its not important\n",
    "# df['error_code'] = np.where(df['error_code']=='ERROR_CODE_NOT_ELIGIBLE_FOR_DELIVERY',131049,df['error_code'])\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format type of data column\n",
    "df['sent_at'] = pd.to_datetime(df['sent_at'], errors='coerce')\n",
    "df['dispatched_at'] = pd.to_datetime(df['dispatched_at'], errors='coerce')\n",
    "df['delivered_at'] = pd.to_datetime(df['delivered_at'], errors='coerce')\n",
    "df['read_at'] = pd.to_datetime(df['read_at'], errors='coerce')\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['error_code'] = np.floor(pd.to_numeric(df['error_code'], errors='coerce')).astype('Int64') #df['error_code'].astype('Int64')\n",
    "\n",
    "#df['Tipo'] = np.where(df['tipo'], \"PRUEBA\", \"LOTE\")\n",
    "#df['Estado'] = np.where(df['estado'], \"VERDADERO\", \"FALSO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1196, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop column\n",
    "df.drop('campaign_name', axis=1, inplace=True)\n",
    "\n",
    "# reorder columns \n",
    "df = df[['customer_external_id', 'campaign_name_base', 'dispatched_at', 'sent_at',\n",
    "       'delivered_at', 'read_at', 'error_code', 'error_msg', 'link_clicks', 'delivered',\n",
    "       'read', 'engagement', 'buy_wsp', 'buy_web', 'buy_web_count', 'buy_wsp_count', 'date',\n",
    "       'day', 'hour']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format datetime\n",
    "df['sent_at'] = df['sent_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df['dispatched_at'] = df['dispatched_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df['delivered_at'] = df['delivered_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df['read_at'] = df['read_at'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as csv\n",
    "# df.to_csv(path_processed+file_name+suffix+file_extension, encoding='utf-8', index=False)\n",
    "\n",
    "df.to_excel(path_processed+file_name+suffix+'.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional)\n",
    "# Export as csv\n",
    "df_diff.to_csv(path_processed+file_name_base+suffix_diff+file_extension)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b4d_analytics-Yg60_lpz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
